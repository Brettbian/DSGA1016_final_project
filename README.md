# DSGA1016_final_project

Flappy Bird:
https://github.com/markub3327/flappy-bird-gymnasium

## Reinforcement learning and Deep Q-Learning
- **Extend the homework to combine RL with convolutional nets.**  In the RL homework you will use the Open AI gym to solve some dynamic control problems from simplified featural representations of the current world state.  However, recent advances in Deep RL allow you use to use raw pixel inputs as features.  One project idea would be to extend the approach in the homework to model learning from the raw pixels of the images.  If you approach that, it is important to maintain a human comparison or element to your project.  For instance, one interesting psychological aspect is to consider how if you alter or obscure parts of the game, it makes it easier or harder for people (while not changing the difficulty for your RL agent) as in the Dubey et al. (preprint) below.  To do this might require a little bit of hacking of the OpenAI environment and also asking your friends to play a few weird video games to measure their performance.

**References**  

The OpenAI Gym: https://gym.openai.com/envs/#atari

Dubey, R., Agrawal, P., Pathak, D., Griffiths, T. L., & Efros, A. A. (preprint). Investigating human priors for playing video games. In Proceedings of the 35th International Conference on Machine Learning (ICML 2018). https://rach0012.github.io/humanRL_website/ (paper and project website)

Flappy-bird-deep-Q-learning-pytorch: https://github.com/uvipen/Flappy-bird-deep-Q-learning-pytorch
